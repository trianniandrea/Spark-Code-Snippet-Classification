{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"streamlit_app.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"9ElDdIvmDiLy"},"source":["# **BIG DATA COMPUTING 2021 PROJECT**\n","\n","# **Code Snippets Classification**\n","## Streamlit based Web application - User interface for PySpark models\n","\n","### Authors: *Andrea Trianni e Emanuele Mercanti*\n","---"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mWa2dVuETywu","executionInfo":{"status":"ok","timestamp":1624866476390,"user_tz":-120,"elapsed":52257,"user":{"displayName":"andrea trianni","photoUrl":"","userId":"04411188180045258312"}},"outputId":"151e01f1-8f14-4c81-f83c-f7841df9b493"},"source":["# Setting java\n","\n","JAVA_HOME = \"/usr/lib/jvm/java-8-openjdk-amd64\" \n","\n","!pip install pyspark -q\n","!pip install -U -q PyDrive -q\n","!apt install openjdk-8-jdk-headless -qq\n","\n","import os\n","os.environ[\"JAVA_HOME\"] = JAVA_HOME"],"execution_count":1,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 212.4MB 73kB/s \n","\u001b[K     |████████████████████████████████| 204kB 20.2MB/s \n","\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","The following additional packages will be installed:\n","  openjdk-8-jre-headless\n","Suggested packages:\n","  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra\n","  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n","  fonts-wqy-zenhei fonts-indic\n","The following NEW packages will be installed:\n","  openjdk-8-jdk-headless openjdk-8-jre-headless\n","0 upgraded, 2 newly installed, 0 to remove and 39 not upgraded.\n","Need to get 36.5 MB of archives.\n","After this operation, 143 MB of additional disk space will be used.\n","Selecting previously unselected package openjdk-8-jre-headless:amd64.\n","(Reading database ... 160772 files and directories currently installed.)\n","Preparing to unpack .../openjdk-8-jre-headless_8u292-b10-0ubuntu1~18.04_amd64.deb ...\n","Unpacking openjdk-8-jre-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n","Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n","Preparing to unpack .../openjdk-8-jdk-headless_8u292-b10-0ubuntu1~18.04_amd64.deb ...\n","Unpacking openjdk-8-jdk-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n","Setting up openjdk-8-jre-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n","Setting up openjdk-8-jdk-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CMDsM_Lrhro4"},"source":[""]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yNRu2BACQ2nk","executionInfo":{"status":"ok","timestamp":1624866528237,"user_tz":-120,"elapsed":16584,"user":{"displayName":"andrea trianni","photoUrl":"","userId":"04411188180045258312"}},"outputId":"474e0cf9-6e29-4b56-baa0-8f7e75c57eb6"},"source":["# Install streamlit + ngrok\n","\n","!pip install streamlit -q\n","\n","!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip ngrok-stable-linux-amd64.zip\n","get_ipython().system_raw('./ngrok http 8501 &')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 7.8MB 7.7MB/s \n","\u001b[K     |████████████████████████████████| 4.2MB 41.5MB/s \n","\u001b[K     |████████████████████████████████| 174kB 53.2MB/s \n","\u001b[K     |████████████████████████████████| 112kB 52.1MB/s \n","\u001b[K     |████████████████████████████████| 81kB 11.8MB/s \n","\u001b[K     |████████████████████████████████| 122kB 50.4MB/s \n","\u001b[K     |████████████████████████████████| 71kB 10.9MB/s \n","\u001b[?25h  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: google-colab 1.0.0 has requirement ipykernel~=4.10, but you'll have ipykernel 5.5.5 which is incompatible.\u001b[0m\n","--2021-06-28 07:48:46--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","Resolving bin.equinox.io (bin.equinox.io)... 34.196.173.159, 54.83.2.115, 3.211.204.50, ...\n","Connecting to bin.equinox.io (bin.equinox.io)|34.196.173.159|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 13832437 (13M) [application/octet-stream]\n","Saving to: ‘ngrok-stable-linux-amd64.zip’\n","\n","ngrok-stable-linux- 100%[===================>]  13.19M  17.4MB/s    in 0.8s    \n","\n","2021-06-28 07:48:47 (17.4 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13832437/13832437]\n","\n","Archive:  ngrok-stable-linux-amd64.zip\n","  inflating: ngrok                   \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"e0lDsKN2gfMY","executionInfo":{"status":"ok","timestamp":1624866537247,"user_tz":-120,"elapsed":4084,"user":{"displayName":"andrea trianni","photoUrl":"","userId":"04411188180045258312"}}},"source":["# Starting pyspark session/context\n","\n","import pyspark\n","from pyspark import SparkContext, SparkConf\n","\n","conf = SparkConf().set(\"spark.ui.port\", \"4050\").set('spark.executor.memory', '4G').set('spark.driver.memory', '12G').set('spark.driver.maxResultSize', '10G')\n","sc = pyspark.SparkContext(conf=conf)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gBKxjnHNUmqV","executionInfo":{"status":"ok","timestamp":1624866541600,"user_tz":-120,"elapsed":2088,"user":{"displayName":"andrea trianni","photoUrl":"","userId":"04411188180045258312"}},"outputId":"b70360a4-afe4-47d8-f2fb-78eebdb15647"},"source":[" # Download python script application + saved models\n","\n"," ! gdown --id 133Hmddmd6ciRkd9WFKmsDYWAJkmFVkAa\n"," ! unzip App.zip -d ."],"execution_count":4,"outputs":[{"output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=133Hmddmd6ciRkd9WFKmsDYWAJkmFVkAa\n","To: /content/App.zip\n","\r  0% 0.00/487k [00:00<?, ?B/s]\r100% 487k/487k [00:00<00:00, 3.25MB/s]\n","Archive:  App.zip\n","   creating: ./App/\n","  inflating: ./App/app.py            \n","   creating: ./App/pipe/\n","   creating: ./App/pipe/tf_model.bin/\n","   creating: ./App/pipe/tf_model.bin/metadata/\n","  inflating: ./App/pipe/tf_model.bin/metadata/_SUCCESS  \n","  inflating: ./App/pipe/tf_model.bin/metadata/._SUCCESS.crc  \n","  inflating: ./App/pipe/tf_model.bin/metadata/.part-00000.crc  \n","  inflating: ./App/pipe/tf_model.bin/metadata/part-00000  \n","   creating: ./App/pipe/tf_model.bin/data/\n","  inflating: ./App/pipe/tf_model.bin/data/_SUCCESS  \n","  inflating: ./App/pipe/tf_model.bin/data/._SUCCESS.crc  \n","  inflating: ./App/pipe/tf_model.bin/data/part-00000-83b04ee1-cb0b-43f8-b639-54c67ad762ce-c000.snappy.parquet  \n","  inflating: ./App/pipe/tf_model.bin/data/.part-00000-83b04ee1-cb0b-43f8-b639-54c67ad762ce-c000.snappy.parquet.crc  \n","   creating: ./App/pipe/idf_model.bin/\n","   creating: ./App/pipe/idf_model.bin/data/\n","  inflating: ./App/pipe/idf_model.bin/data/_SUCCESS  \n","  inflating: ./App/pipe/idf_model.bin/data/._SUCCESS.crc  \n","  inflating: ./App/pipe/idf_model.bin/data/.part-00000-e7b98d98-8d9b-413a-a4e7-a219aec4a7bc-c000.snappy.parquet.crc  \n","  inflating: ./App/pipe/idf_model.bin/data/part-00000-e7b98d98-8d9b-413a-a4e7-a219aec4a7bc-c000.snappy.parquet  \n","   creating: ./App/pipe/idf_model.bin/metadata/\n","  inflating: ./App/pipe/idf_model.bin/metadata/_SUCCESS  \n","  inflating: ./App/pipe/idf_model.bin/metadata/._SUCCESS.crc  \n","  inflating: ./App/pipe/idf_model.bin/metadata/.part-00000.crc  \n","  inflating: ./App/pipe/idf_model.bin/metadata/part-00000  \n","  inflating: ./App/pipe/class_weigths.json  \n","  inflating: ./App/pipe/target_dict.json  \n","   creating: ./App/pipe/bow_vectorizer.bin/\n","   creating: ./App/pipe/bow_vectorizer.bin/data/\n","  inflating: ./App/pipe/bow_vectorizer.bin/data/_SUCCESS  \n","  inflating: ./App/pipe/bow_vectorizer.bin/data/._SUCCESS.crc  \n","  inflating: ./App/pipe/bow_vectorizer.bin/data/.part-00000-3ac69ab9-9d84-4d31-837e-4366b9d7ce73-c000.snappy.parquet.crc  \n","  inflating: ./App/pipe/bow_vectorizer.bin/data/part-00000-3ac69ab9-9d84-4d31-837e-4366b9d7ce73-c000.snappy.parquet  \n","   creating: ./App/pipe/bow_vectorizer.bin/metadata/\n","  inflating: ./App/pipe/bow_vectorizer.bin/metadata/_SUCCESS  \n","  inflating: ./App/pipe/bow_vectorizer.bin/metadata/._SUCCESS.crc  \n","  inflating: ./App/pipe/bow_vectorizer.bin/metadata/part-00000  \n","  inflating: ./App/pipe/bow_vectorizer.bin/metadata/.part-00000.crc  \n","   creating: ./App/model.bin/\n","   creating: ./App/model.bin/data/\n","  inflating: ./App/model.bin/data/_SUCCESS  \n","  inflating: ./App/model.bin/data/._SUCCESS.crc  \n","  inflating: ./App/model.bin/data/.part-00000-1c55f48f-0f49-40f2-b623-0aa472a29420-c000.snappy.parquet.crc  \n","  inflating: ./App/model.bin/data/part-00000-1c55f48f-0f49-40f2-b623-0aa472a29420-c000.snappy.parquet  \n","   creating: ./App/model.bin/metadata/\n","  inflating: ./App/model.bin/metadata/_SUCCESS  \n","  inflating: ./App/model.bin/metadata/._SUCCESS.crc  \n","  inflating: ./App/model.bin/metadata/part-00000  \n","  inflating: ./App/model.bin/metadata/.part-00000.crc  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LqLWXXVTzpvR","executionInfo":{"status":"ok","timestamp":1624866545666,"user_tz":-120,"elapsed":244,"user":{"displayName":"andrea trianni","photoUrl":"","userId":"04411188180045258312"}},"outputId":"bbb25dd6-2754-4961-9041-b4e5d9cd48a3"},"source":["# Retrieve public URL to website:\n","\n","!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    'import sys, json; print(\"Execute the next cell and then please connect to the following URL: \" +json.load(sys.stdin)[\"tunnels\"][0][\"public_url\"])'"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Execute the next cell and then please connect to the following URL: http://f67d6ed63a2c.ngrok.io\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T796sEHyQ_Ac","executionInfo":{"status":"ok","timestamp":1624871372764,"user_tz":-120,"elapsed":4825296,"user":{"displayName":"andrea trianni","photoUrl":"","userId":"04411188180045258312"}},"outputId":"80ae08aa-f4d2-4152-b4b3-7d80ed346486"},"source":["# Run the application\n","\n","%cd ./App\n","!streamlit run ./app.py"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/content/App\n","\u001b[0m\n","\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n","\u001b[0m\n","\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.2:8501\u001b[0m\n","\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.125.0.26:8501\u001b[0m\n","\u001b[0m\n","21/06/28 07:49:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n","Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n","Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","21/06/28 07:49:12 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n","21/06/28 07:49:47 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n","21/06/28 07:49:47 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n","2021-06-28 08:49:01.120 Got an empty FileUploader widget_value. (We expect a list with at least one value in it.)\n","\u001b[34m  Stopping...\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AYN0Kfe8w5G6"},"source":["# test html \n","\"\"\"\n","<div id=\"root\"><div class=\"\">)<div class=\"withScreencast\"><div tabindex=\"-1\"><div class=\"stApp css-h9oeas eczokvf0\"><header tabindex=\"-1\" class=\"css-1moshnm e8zbici0\"><div data-testid=\"stDecoration\" class=\"css-kywgdc e8zbici1\"></div><div data-testid=\"stToolbar\" class=\"css-r698ls e8zbici2\"><span id=\"MainMenu\" aria-haspopup=\"true\" aria-expanded=\"false\"><button kind=\"icon\" class=\"css-1iyw2u1 edgvbvh\n","\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g-wojRAM07lr"},"source":["# test rust \n","\n","\"\"\"\n","fn main() {\n","    let an_integer = 1u32;\n","    let a_boolean = true;\n","    let unit = ();\n","\n","    // copy `an_integer` into `copied_integer`\n","    let copied_integer = an_integer;\n","\n","    println!(\"An integer: {:?}\", copied_integer);\n","    println!(\"A boolean: {:?}\", a_boolean);\n","    println!(\"Meet the unit value: {:?}\", unit);\n","\n","    // The compiler warns about unused variable bindings; these warnings can\n","    // be silenced by prefixing the variable name with an underscore\n","    let _unused_variable = 3u32;\n","\n","    let noisy_unused_variable = 2u32;\n","    // FIXME ^ Prefix with an underscore to suppress the warning\n","}\n","\n","\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oNz3zBR2xIrA"},"source":["# test python \n","\"\"\"\n","\n","import pyspark\n","from pyspark import SparkContext, SparkConf\n","\n","conf = SparkConf().set(\"spark.ui.port\", \"4050\").set('spark.executor.memory', '4G').set('spark.driver.memory', '12G').set('spark.driver.maxResultSize', '10G')\n","sc = pyspark.SparkContext(conf=conf)\n","\n","\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"06XEVjRow-h1"},"source":["# test javascript\n","\"\"\"\n","turn __generator(this, function (_a) {\n","        switch (_a.label) {\n","            case 0:\n","                email = req.body.email;\n","                token = req.body.token;\n","                return [4 /*yield*/, models_1.Restaurant.find({ \"email\": email }).exec()];\n","            case 1:\n","                query = _a.sent();\n","                // Checking if the restaurant is registered\n","                if (query.length == 0) {\n","                    res.send({ \"error\": \"There is no restaurant registered with this email address.\" });\n","                    return [2 /*return*/];\n","                }\n","                restaurant = query[0];\n","                // Deleting token\n","                restaurant.tokens.forEach(function (current, index) {\n","                    if (token === current) {\n","\n","\"\"\""],"execution_count":null,"outputs":[]}]}